---
layout: post
title:  "Hadoop 3.2.1 单节点配置"
subtitle: '何设置和配置单节点Hadoop安装'
date:   2020-07-27 20:00:21 +0800
tags: Hadoop
color: rgb(255,90,90)
cover: '../assets/20200727/cover.jpg'
---


## 准备相关环境
1. 安装openJDK

   ```
   yum install java-1.8.0-openjdk* -y
   ```

2. 安装ssh和pdsh

   ```
   yum install ssh -y
   yum install pdsh -y
   ```

3. 解压Hadoop压缩包

   ```
   tar -zxvf hadoop-3.2.1.tar.gz -C /opt/
   ```
4. 指定jdk路径
   
   ```
   cd /opt/hadoop-3.2.1/etc/hadoop
   vim hadoop-env.sh
   ```
   ![java](/assets/20200727/export_java.jpg)

5. 查看Hadoop版本
   
   在hadoop根目录，这里是/opt/hadoop-3.2.1/,运行一下指令查看版本信息，测试Hadoop是否能运行

   ```
   bin/hadoop version
   ```

6. 配置Hadoop环境变量

   ```
   vim ~/.bashrc
   ```
   输入以下内容
   ```
   export HADOOP_HOME=/opt/hadoop-3.2.1
   export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
   ```
   ![env](/assets/20200727/hadoop_env.jpg)
   然后运行以下命令应用
   ```
   source ~/.bashrc
   ```

7. 需要配置ssh免密登录
   ```
   ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
   cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
   chmod 0600 ~/.ssh/authorized_keys

   ssh-keygen 
   ssh-copy-id 远程ip地址
   ```

## 本地模式

执行官方的示例：

```
mkdir input
cp etc/hadoop/*.xml input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+'
cat output/*
```

## 伪分布模式

> 以下命令工作的路径都为$HADOOP_HOME/

1. 配置文件etc/hadoop/core-site.xml

   输入以下内容：
   ```
   <configuration>
      <property>
         <name>fs.defaultFS</name>
         <value>hdfs://localhost:9000</value>
      </property>
   </configuration>
   ```
   ![xml](/assets/20200727/core_xml.jpg)

2. 配置文件etc/hadoop/hdfs-site.xml

   输入以下内容：
   ```
   <configuration>
      <property>
         <name>dfs.replication</name>
         <value>1</value>
      </property>
   </configuration>
   ```
   ![xml](/assets/20200727/hdfs_xml.jpg)

3. 格式化 namenode
   ```
   bin/hdfs namenode -format
   ```

4. 修改start-dfs.sh和stop-dfs.sh内容
   
   加入以下语句：
   ```
   HDFS_DATANODE_USER=root
   HADOOP_SECURE_DN_USER=hdfs
   HDFS_NAMENODE_USER=root
   HDFS_SECONDARYNAMENODE_USER=root
   ```
   ![dfs](/assets/20200727/sh1.jpg)

5. 运行start-dfs.sh脚本，启动namenode和datanode守护进程

   ```
   sbin/start-dfs.sh
   ```
   输入jps命令，可以看到守护进程已启动
   ![daemon](/assets/20200727/daemon_suc.jpg)

6. 在HDFS上创建执行MapReduce作业所需要的文件夹
   ```
   bin/hdfs dfs -mkdir /user
   bin/hdfs dfs -mkdir /user/<username>
   ```
   ![dir](/assets/20200727/mkdir.jpg)

7. 执行一个作业尝试（官方示例）
   
   输入以下命令
   ```
   bin/hdfs dfs -mkdir input
   bin/hdfs dfs -put etc/hadoop/*.xml input
   bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+'
   bin/hdfs dfs -get output output
   cat output/*
   bin/hdfs dfs -cat output/*
   ```
   作业完成后可以使用
   ```
   bin/hdfs dfs -ls
   ```
   命令，查看hdfs中的文件
   ![hdfs](/assets/20200727/ls_hdfs.jpg)

8. 停止namenode和datanode守护进程
   ```
   sbin/stop-dfs.sh
   ```

## YARN配置伪分布式模式

> 以下命令工作的路径都为$HADOOP_HOME/

1. 配置文件etc/hadoop/mapred-site.xml
   ```
   <configuration>
      <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
      </property>
      <property>
         <name>mapreduce.application.classpath</name>
         <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
      </property>
   </configuration>
   ```
   ![xml](/assets/20200727/m_xml.jpg)

2. 配置文件etc/hadoop/yarn-site.xml
   ```
   <configuration>
      <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
      </property>
      <property>
         <name>yarn.nodemanager.env-whitelist</name>
         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
      </property>
   </configuration>
   ```
   ![xml](/assets/20200727/yarn_xml.jpg)

3. 修改start-yarn.sh和stop-yarn.sh内容
   
   加入以下语句：
   ```
   YARN_RESOURCEMANAGER_USER=root
   HADOOP_SECURE_DN_USER=yarn
   YARN_NODEMANAGER_USER=root
   ```
   ![yarn](/assets/20200727/yarn_sh.jpg)

4. 运行start-yarn.sh脚本，启动ResourceManager 和NodeManager 守护进程
   ```
   sbin/start-yarn.sh
   ```
   ![yarn](/assets/20200727/yarn_daemon.jpg)

5. 停止ResourceManager 和NodeManager 守护进程
   ```
   sbin/stop-yarn.sh
   ```